# k8s/monitoring/alertmanager-servicenow-config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-kube-prometheus-stack-alertmanager-generated
  namespace: monitoring
type: Opaque
stringData:
  alertmanager.yaml: |
    global:
      resolve_timeout: 5m
    
    route:
      receiver: 'servicenow-incidents'
      group_by: ['alertname', 'namespace', 'severity']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      routes:
      # Critical alerts - immediate notification
      - receiver: 'servicenow-incidents'
        matchers:
        - severity =~ "critical|high"
        group_wait: 10s
        repeat_interval: 4h
      
      # Warning alerts - grouped notification
      - receiver: 'servicenow-incidents'
        matchers:
        - severity = "warning"
        group_wait: 2m
        repeat_interval: 12h
      
      # Info alerts - daily digest
      - receiver: 'servicenow-incidents'
        matchers:
        - severity = "info"
        group_wait: 5m
        repeat_interval: 24h
    
    receivers:
    - name: 'servicenow-incidents'
      webhook_configs:
      - url: 'http://servicenow-webhook.servicenow-integration.svc.cluster.local/webhook'
        send_resolved: true
        http_config:
          follow_redirects: true
        max_alerts: 0
    
    inhibit_rules:
    # Inhibit warning if critical is firing for same alert
    - source_matchers:
      - severity = "critical"
      target_matchers:
      - severity = "warning"
      equal:
      - alertname
      - namespace
      - instance
    
    # Inhibit info if warning is firing
    - source_matchers:
      - severity = "warning"
      target_matchers:
      - severity = "info"
      equal:
      - alertname
      - namespace
      - instance